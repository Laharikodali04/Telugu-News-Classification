{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozrcI3_k-pKW",
        "outputId": "cadf84d9-8541-4e21-8c6a-9cc211963a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy scikit-learn tensorflow gensim transformers datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy\n",
        "import sklearn\n",
        "import tensorflow\n",
        "import gensim\n",
        "import transformers\n",
        "import datasets\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fppr8m1rA-Hs",
        "outputId": "9d060548-8e10-4c40-89cb-7b1074d30fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Baseline Telugu News Classification using Word2Vec + ML/DL Models\n",
        "Models: MLP, CNN, LSTM, BiLSTM\n",
        "Dataset: train and test CSVs in telugu_news folder\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (Embedding, Dense, LSTM, Bidirectional, Conv1D,\n",
        "                                     GlobalMaxPooling1D, Dropout, Flatten)\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# ------------------ Config ------------------\n",
        "TRAIN_PATH = \"/content/train_telugu_news.csv\"\n",
        "TEST_PATH = \"/content/test_telugu_news.csv\"\n",
        "MAX_VOCAB = 20000\n",
        "MAX_LEN = 200\n",
        "EMBEDDING_DIM = 100\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "# --------------------------------------------\n",
        "\n",
        "# 1) Read Dataset and Combine Text\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "def merge_text(row):\n",
        "    return f\"{str(row['heading'])} - {str(row['body'])}\"\n",
        "\n",
        "train_df[\"text\"] = train_df.apply(merge_text, axis=1)\n",
        "test_df[\"text\"] = test_df.apply(merge_text, axis=1)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "train_df[\"label\"] = le.fit_transform(train_df[\"topic\"])\n",
        "test_df[\"label\"] = le.transform(test_df[\"topic\"])\n",
        "\n",
        "NUM_CLASSES = len(le.classes_)\n",
        "print(\"Classes:\", list(le.classes_))\n",
        "\n",
        "# 2) Tokenization and Padding\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_df[\"text\"])\n",
        "\n",
        "train_seq = tokenizer.texts_to_sequences(train_df[\"text\"])\n",
        "test_seq = tokenizer.texts_to_sequences(test_df[\"text\"])\n",
        "\n",
        "x_train = pad_sequences(train_seq, maxlen=MAX_LEN)\n",
        "x_test = pad_sequences(test_seq, maxlen=MAX_LEN)\n",
        "y_train = train_df[\"label\"].values\n",
        "y_test = test_df[\"label\"].values\n",
        "\n",
        "# 3) Train Word2Vec for embeddings\n",
        "sentences = [text.split() for text in train_df[\"text\"]]\n",
        "w2v_model = Word2Vec(sentences, vector_size=EMBEDDING_DIM, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Build embedding matrix\n",
        "word_index = tokenizer.word_index\n",
        "embedding_matrix = np.zeros((MAX_VOCAB, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i < MAX_VOCAB:\n",
        "        if word in w2v_model.wv:\n",
        "            embedding_matrix[i] = w2v_model.wv[word]\n",
        "        else:\n",
        "            embedding_matrix[i] = np.random.normal(scale=0.6, size=(EMBEDDING_DIM,))\n",
        "\n",
        "# 4) Define Models\n",
        "\n",
        "def build_mlp():\n",
        "    model = Sequential([\n",
        "        Embedding(MAX_VOCAB, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dropout(0.3),\n",
        "        Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_cnn():\n",
        "    model = Sequential([\n",
        "        Embedding(MAX_VOCAB, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False),\n",
        "        Conv1D(128, 5, activation=\"relu\"),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_lstm():\n",
        "    model = Sequential([\n",
        "        Embedding(MAX_VOCAB, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False),\n",
        "        LSTM(128),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_bilstm():\n",
        "    model = Sequential([\n",
        "        Embedding(MAX_VOCAB, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False),\n",
        "        Bidirectional(LSTM(128)),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# 5) Train and Evaluate Models\n",
        "models = {\n",
        "    \"MLP\": build_mlp(),\n",
        "    \"CNN\": build_cnn(),\n",
        "    \"LSTM\": build_lstm(),\n",
        "    \"BiLSTM\": build_bilstm()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} model...\")\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    model.fit(x_train, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
        "\n",
        "    print(f\"Evaluating {name}...\")\n",
        "    y_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
        "\n",
        "    results[name] = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "    print(f\"\\n{name} Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "# 6) Print Summary Table\n",
        "print(\"\\n\\n=== Final Results Summary ===\")\n",
        "for model, metrics in results.items():\n",
        "    print(f\"{model}: {metrics}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCNCiJ9BBDKw",
        "outputId": "2b05b2fa-c3e4-453c-96b8-de6fb3fb59b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['business', 'editorial', 'entertainment', 'nation', 'sports']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training MLP model...\n",
            "Epoch 1/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.7601 - loss: 0.8099 - val_accuracy: 0.8562 - val_loss: 0.4243\n",
            "Epoch 2/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 31ms/step - accuracy: 0.8905 - loss: 0.3175 - val_accuracy: 0.8707 - val_loss: 0.3918\n",
            "Epoch 3/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9210 - loss: 0.2253 - val_accuracy: 0.8776 - val_loss: 0.3992\n",
            "Epoch 4/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9358 - loss: 0.1730 - val_accuracy: 0.8759 - val_loss: 0.4520\n",
            "Epoch 5/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - accuracy: 0.9495 - loss: 0.1394 - val_accuracy: 0.8764 - val_loss: 0.4157\n",
            "Evaluating MLP...\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\n",
            "MLP Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.86      0.79      0.83       653\n",
            "    editorial       0.72      0.78      0.75       277\n",
            "entertainment       0.97      0.94      0.96      1289\n",
            "       nation       0.85      0.89      0.87      1673\n",
            "       sports       0.85      0.82      0.83       437\n",
            "\n",
            "     accuracy                           0.88      4329\n",
            "    macro avg       0.85      0.85      0.85      4329\n",
            " weighted avg       0.88      0.88      0.88      4329\n",
            "\n",
            "\n",
            "Training CNN model...\n",
            "Epoch 1/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 45ms/step - accuracy: 0.7888 - loss: 0.6756 - val_accuracy: 0.8851 - val_loss: 0.3151\n",
            "Epoch 2/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 49ms/step - accuracy: 0.9154 - loss: 0.2471 - val_accuracy: 0.8967 - val_loss: 0.2841\n",
            "Epoch 3/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.9323 - loss: 0.1953 - val_accuracy: 0.9082 - val_loss: 0.2847\n",
            "Epoch 4/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 44ms/step - accuracy: 0.9438 - loss: 0.1609 - val_accuracy: 0.9186 - val_loss: 0.2567\n",
            "Epoch 5/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.9541 - loss: 0.1366 - val_accuracy: 0.9111 - val_loss: 0.2812\n",
            "Evaluating CNN...\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n",
            "\n",
            "CNN Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.94      0.82      0.87       653\n",
            "    editorial       0.81      0.68      0.74       277\n",
            "entertainment       0.97      0.96      0.97      1289\n",
            "       nation       0.88      0.94      0.91      1673\n",
            "       sports       0.88      0.93      0.90       437\n",
            "\n",
            "     accuracy                           0.91      4329\n",
            "    macro avg       0.90      0.87      0.88      4329\n",
            " weighted avg       0.91      0.91      0.91      4329\n",
            "\n",
            "\n",
            "Training LSTM model...\n",
            "Epoch 1/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 236ms/step - accuracy: 0.7918 - loss: 0.5919 - val_accuracy: 0.8943 - val_loss: 0.3232\n",
            "Epoch 2/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 236ms/step - accuracy: 0.8961 - loss: 0.3025 - val_accuracy: 0.8932 - val_loss: 0.3001\n",
            "Epoch 3/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 235ms/step - accuracy: 0.9228 - loss: 0.2303 - val_accuracy: 0.9186 - val_loss: 0.2332\n",
            "Epoch 4/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 236ms/step - accuracy: 0.9332 - loss: 0.1837 - val_accuracy: 0.9307 - val_loss: 0.2017\n",
            "Epoch 5/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 237ms/step - accuracy: 0.9428 - loss: 0.1571 - val_accuracy: 0.9411 - val_loss: 0.1851\n",
            "Evaluating LSTM...\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 87ms/step\n",
            "\n",
            "LSTM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.96      0.84      0.89       653\n",
            "    editorial       0.88      0.90      0.89       277\n",
            "entertainment       0.98      0.97      0.97      1289\n",
            "       nation       0.90      0.96      0.93      1673\n",
            "       sports       0.97      0.93      0.95       437\n",
            "\n",
            "     accuracy                           0.94      4329\n",
            "    macro avg       0.94      0.92      0.93      4329\n",
            " weighted avg       0.94      0.94      0.94      4329\n",
            "\n",
            "\n",
            "Training BiLSTM model...\n",
            "Epoch 1/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 462ms/step - accuracy: 0.8146 - loss: 0.5613 - val_accuracy: 0.8533 - val_loss: 0.4653\n",
            "Epoch 2/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 501ms/step - accuracy: 0.9000 - loss: 0.2979 - val_accuracy: 0.9099 - val_loss: 0.2718\n",
            "Epoch 3/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 493ms/step - accuracy: 0.9257 - loss: 0.2189 - val_accuracy: 0.9163 - val_loss: 0.2439\n",
            "Epoch 4/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 485ms/step - accuracy: 0.9293 - loss: 0.1948 - val_accuracy: 0.9296 - val_loss: 0.2153\n",
            "Epoch 5/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 489ms/step - accuracy: 0.9464 - loss: 0.1547 - val_accuracy: 0.9319 - val_loss: 0.1953\n",
            "Evaluating BiLSTM...\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 147ms/step\n",
            "\n",
            "BiLSTM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.87      0.95      0.91       653\n",
            "    editorial       0.86      0.89      0.88       277\n",
            "entertainment       0.98      0.98      0.98      1289\n",
            "       nation       0.95      0.91      0.93      1673\n",
            "       sports       0.95      0.95      0.95       437\n",
            "\n",
            "     accuracy                           0.94      4329\n",
            "    macro avg       0.92      0.94      0.93      4329\n",
            " weighted avg       0.94      0.94      0.94      4329\n",
            "\n",
            "\n",
            "\n",
            "=== Final Results Summary ===\n",
            "MLP: {'accuracy': 0.8773388773388774, 'precision': 0.8792185496281915, 'recall': 0.8773388773388774, 'f1': 0.8777429025715306}\n",
            "CNN: {'accuracy': 0.9101409101409101, 'precision': 0.9107685537667962, 'recall': 0.9101409101409101, 'f1': 0.9090103008038269}\n",
            "LSTM: {'accuracy': 0.9376299376299376, 'precision': 0.9392998615651005, 'recall': 0.9376299376299376, 'f1': 0.9374161551341962}\n",
            "BiLSTM: {'accuracy': 0.9413259413259413, 'precision': 0.9426019206783235, 'recall': 0.9413259413259413, 'f1': 0.9415057003953584}\n"
          ]
        }
      ]
    }
  ]
}